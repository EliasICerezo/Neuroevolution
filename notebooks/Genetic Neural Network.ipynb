{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Neural Network Implementation\n",
    "Nowadays Neural Networks aim to optimize a certain objective function in order to use it as a feature extractor, a classifier or as a regression tool. This function is usually optimized using a stochastic gradient descent method as backpropagation. However, there are a lot of alternatives to the backpropagation procedure.  \n",
    "In this notebook we will introduce a neural network whose weights are optimized using a Genetic Algorithm.\n",
    "\n",
    "## Use Case Scenario \n",
    "A neural network can be represented from different points of view. In this notebook we want to represent it as a set of arrays that ensemble the weights and the biases of the network. Depending on the complexity of the structure proposed, these variables will scale in number and size, so it must be taken in consideration prior to build a deep neural network.  \n",
    "The neural network that we are going to build in this notebook is a fully connected one, that means, that every neuron from one layer is connected to all the neurons of the following layer. Every neural network encoding will be an individual of our population in our genetic algorithms implementation.  \n",
    "The rest of the notebook contains, a specification of the neural network, explanation of the algorithm and a proof that the algorithm actually works as intended.\n",
    "\n",
    "## Genetic Algorithms\n",
    "Genetic Algoritms are a metaheuristic that uses different individuals to explore the search space with different individuals in order to find the local minimum of the function. These individuals move across the search space using genetic operators.   \n",
    "Mutation, Crossover and Selection are the three main genetic operators in any genetic algorithm. They allow the solutions population to move across the search space and eventually finding the global minimum of the objective function.  \n",
    "These three operators take different forms depending on how you represent the data that ensembles the population that navigates the search space. In this project we have implemented them as it follows:  \n",
    "* Mutation operators take an index of the weight or bias that is going to be modified and with a certain probability mutates the weight with a random operator. This will make sense once we see the operators.\n",
    "* Selection operator takes the population and all its individuals and select those who are the fittest, although it may not be the best option as we will see in the conclusion area\n",
    "* Crossover operator takes 2 different solutions of the population and combines them to form 2 new solutions.\n",
    "\n",
    "## Mutation Operators\n",
    "In this section we are going to see how the mutations are made to the different solutions, what we effectively call the mutation operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_rand_value(weights,low = -2, high = 2):\n",
    "  \"\"\"A function that generates a random value and index just for using them in \n",
    "  the substitution funcions blow\n",
    "  \n",
    "  Arguments:\n",
    "      weights {np.array} -- The weight array where the function will choose a \n",
    "      position\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      low {int} -- The lower bound to generate the random value (default: {-2})\n",
    "      high {int} -- The higher bound to generate the random value (default: {2})\n",
    "  \n",
    "  Returns:\n",
    "      index, random_value -- The selected index of the weights to be changed and\n",
    "      the random number generated with the bounds above\n",
    "  \"\"\"\n",
    "  index = []\n",
    "  for i in range(len(weights.shape)):\n",
    "    index.append(np.random.randint(0,weights.shape[i] ))\n",
    "  index =  tuple(index)\n",
    "  random_value = np.random.uniform(low=low,high=high)\n",
    "  return index,random_value\n",
    "\n",
    "def randomize_a_weight(weights:np.array):\n",
    "  \"\"\"Mutates the weights changing one of them for a random value between a scale\n",
    "  \n",
    "  Arguments:\n",
    "      weights {np.array} -- The weights of the neural network to be mutated\n",
    "  \n",
    "  Returns:\n",
    "      weights -- The weights with the mutation \n",
    "  \"\"\"\n",
    "  index, random_value = generate_rand_value(weights)\n",
    "  weights.put(index,random_value)\n",
    "  return weights\n",
    "\n",
    "def add_a_weighted_random_value(weights:np.array, percentage = 0.1):\n",
    "  \"\"\"Mutates a single weight by a factor\n",
    "  \n",
    "  Arguments:\n",
    "      weights {np.array} -- The weights array to be mutated\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      percentage {float} -- The percentage that the weights will be mutated by \n",
    "      the random value generated (default: {0.1})\n",
    "  \n",
    "  Returns:\n",
    "      weights -- The mutated weight array.\n",
    "  \"\"\"\n",
    "  index, random_value = generate_rand_value(weights)\n",
    "  weights.put(index, random_value*percentage)\n",
    "  return weights\n",
    "\n",
    "def add_or_substract_a_random_value(weights:np.array):\n",
    "  \"\"\"Mutation operator that adds or substracts a random value to the weight\n",
    "  \n",
    "  Arguments:\n",
    "      weights {np.array} -- weight array\n",
    "  \n",
    "  Returns:\n",
    "      weights -- Updated weights\n",
    "  \"\"\"\n",
    "  index,random_value = generate_rand_value(weights,0,1)\n",
    "  add_or_sbstract = np.random.randint(0,2)\n",
    "  if add_or_sbstract == 0:\n",
    "    add_or_sbstract = -1\n",
    "  weights.put(index, (weights[index])*(random_value*add_or_sbstract))\n",
    "  return weights\n",
    "\n",
    "def change_sign_of_a_weight(weights:np.array):\n",
    "  \"\"\"Changes the sign of a weight\n",
    "  \n",
    "  Arguments:\n",
    "      weights {np.array} -- weight array\n",
    "  \"\"\"\n",
    "  index, _ = generate_rand_value(weights)\n",
    "  weights.put(index, -weights[index])\n",
    "  return weights\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the code cell above, we define 4 different operators and a helper method.  \n",
    "The helper method selects a random weight or bias and generates a reandom value to be used by the operator itself.  \n",
    "The first operator takes the index of the weight or bias and assigns the random value generated to it.\n",
    "The second operator does the same that the first one but instead of assigning directly the value, it is multiplied by a certain percentage.\n",
    "The third operator, takes the index and adds or substract randomly the value generated.\n",
    "The fourth operator takes the index generated and changes the sign of the weight or bias.  \n",
    "As you can see they are different, and there are a lot of mutation operators that we can add to this, and since they are selected randomly, it is very simple to implement whatever operator that you can imagine.  \n",
    "Now we are going to see how the crossover operator is implemented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def single_point_crossover(w1: np.array,w2: np.array):\n",
    "  \"\"\"Crossover operator that uses a single point as the divisor for the crossover\n",
    "  operation. It makes an horizontal split between the 2 arrays provided to the\n",
    "  method\n",
    "  \n",
    "  Arguments:\n",
    "      w1 {np.array} -- 1st array of weights what is going to be used.\n",
    "      w2 {np.array} -- 2nd array of weights what is going to be used.\n",
    "  \n",
    "  Raises:\n",
    "      AttributeError: If the shapes do not match\n",
    "  \n",
    "  Returns:\n",
    "      w1,w1 -- new arrays of weights ensambling new behaviour\n",
    "  \"\"\"\n",
    "  if w1.shape != w2.shape:\n",
    "    raise AttributeError(\"Shapes must be the same if we are going to crossover\")\n",
    "  crossover_point = np.random.randint(0, w1.shape[0])\n",
    "  w1_splitted = np.split(w1, [crossover_point])\n",
    "  w2_splitted = np.split(w2, [crossover_point])\n",
    "  w1_ensembled = np.concatenate([w1_splitted[0], w2_splitted[1]])\n",
    "  w2_ensembled = np.concatenate([w2_splitted[0], w1_splitted[1]])\n",
    "  return (w1_ensembled, w2_ensembled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the code cell above, we implement a single point crossover, we take the point randomly in the vector passed, and combine the vectors.\n",
    "Similar to the mutation operators you can implement any crossover operator, but in this case the only one that has been implemented is the single point crossover one.  \n",
    "Lastly let's revise the selection operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_operator(self, division:float = 5):\n",
    "    \"\"\"Operator that represent the natural selection where they will only survive\n",
    "    the 20% of the offspring with the best fitness, that is the minimum loss.\n",
    "    \"\"\"\n",
    "    if len(self.population.keys()) <= self.max_pop_size//6:\n",
    "      return\n",
    "    reduce__dict = (\n",
    "        lambda x: {\n",
    "            k:v for index,(k,v) in enumerate(x.items())\n",
    "            if index<=self.max_pop_size//division\n",
    "        })\n",
    "    self.population = reduce__dict(self.population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above we define the selection operator as the reduction in population by keeping the factor that makes the division of the current number of individuals by the value passed in the method.  \n",
    "Taking all of these operators, let's see how they interact in the training procedure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, inputs: np.ndarray, targets: np.ndarray, max_iter: int):\n",
    "    \"\"\"Training function that defines the evolutive behaviour of the neural net.\n",
    "    \n",
    "    Arguments:\n",
    "        inputs {np.ndarray} -- Input arrays in the form of arrays\n",
    "        targets {np.ndarray} -- The values desired fot those inputs\n",
    "        max_iter {int} -- Maximum number of iterations that the nnet will be \n",
    "        running.\n",
    "    \"\"\"\n",
    "    for i in range(max_iter):\n",
    "      activated_results = self.evolved_feed_forward(inputs)\n",
    "      self.calculate_loss(activated_results, targets)\n",
    "      \n",
    "      # Selection operator\n",
    "      if len(self.population.keys()) > self.max_pop_size or np.random.randint(0,101) < SELECTION_PROBABILITY:\n",
    "        self.selection_operator()\n",
    "      # Mutation operator (it mutates weights and biases)\n",
    "      self.mutate_population()\n",
    "      # Crossover operator\n",
    "      self.crossover_populations('W')\n",
    "      self.crossover_populations('b')\n",
    "      self.population.update(self.additions)\n",
    "      self.additions = {}\n",
    "      self.sort_population()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above we can see that the training procedure is executed during max_iter time, and we mutate the population, apply crossover, sort the population and if the conditions are met, use selection to reduce the population.\n",
    "* mutate_population is a method that tests if every weight and bias in the population is eligible for mutation using certain probability.\n",
    "* crossover_populations is a method that tests if 2 individuals are eligible for crossover with certain probability.\n",
    "* additions is the dictionary that takes every mutation and crossover and stores it until the end of the iteration, since if we don't do this we could enter an infinite cycle.\n",
    "* sort_populations is a method that sorts the population out by the loss value, being loss the objective function value given by that neural network with that weights and biases.\n",
    "* calculate_loss is the function whose responsability is to store in every individual its loss value.\n",
    "\n",
    "## Genetic Neural Network Demo.\n",
    "In this section we will present a python program that is going to provide us the correct instructions in order to obtain results from this genetic neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Jupyter to use correctly the path related to the code\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from neuroevolution.networks.genetic_neural_network import GeneticNeuralNetwork\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    feature_set = np.array([[0,1,0],[0,0,1],[1,0,0],[1,1,0],[1,1,1]])\n",
    "    labels = np.array([[1,0,0,1,1]])\n",
    "    labels = labels.reshape(5,1)\n",
    "    nnet = GeneticNeuralNetwork(layers=[3,1], input_size=3, num_of_classes= 1)\n",
    "    nnet.train(feature_set,labels, 100)\n",
    "    vs = nnet.population.values()\n",
    "    vs = list(vs)\n",
    "    for i in vs: print(i['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIP:\n",
    "    Conclusions  \n",
    "    Revision  \n",
    "    Loss printing in other format more friendly  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
